{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib as mplt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('input_data/y/Yrep1.csv', sep=';', header=None)\n",
    "Q = pd.read_csv('input_data/qmatrix/Qmatrix.csv', sep=';', header=None)\n",
    "Q = Q.T\n",
    "data = data.values.reshape((90, 10000)).transpose()\n",
    "print(data.shape)\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict connection in decoder\n",
    "def q_constraint(w):\n",
    "    target = w * Q\n",
    "    diff = w - target\n",
    "    w = w * tf.cast(tf.math.equal(diff, 0), keras.backend.floatx()) \n",
    "    return w * tf.cast(tf.math.greater_equal(w, 0), keras.backend.floatx())\n",
    "\n",
    "# Remove zeros function\n",
    "def remove_zeros(arr):\n",
    "  n_arr = []\n",
    "  \n",
    "  for j in range(NUM_SKILLS): \n",
    "    for i in range(NUM_STATS):\n",
    "      if Q.iloc[j, i] != 0:\n",
    "        n_arr.append(arr[j][i])\n",
    "  \n",
    "  return n_arr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = int(data.shape[0] * 0.8)\n",
    "vl = int(data.shape[0] * 0.9)\n",
    "ntest = data[tr: vl, :]\n",
    "ntrain = data[:tr, :]\n",
    "nval = data[vl:, :]\n",
    "print(ntrain.shape)\n",
    "print(ntest.shape)\n",
    "print(nval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stats and skills\n",
    "NUM_STATS = 90\n",
    "NUM_SKILLS = 21\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BUFFER_SIZE = 1024\n",
    "\n",
    "INTERMEDIATE_DIM = 40\n",
    "\n",
    "# Encoder and Decoder\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "ENC_PROJECTION_DIM = 1\n",
    "DEC_PROJECTION_DIM = 18\n",
    "ENC_NUM_HEADS = 4\n",
    "ENC_LAYERS = 6\n",
    "DEC_NUM_HEADS = 4\n",
    "DEC_LAYERS = (\n",
    "    2  # The decoder is lightweight but should be reasonably deep for reconstruction.\n",
    ")\n",
    "ENC_TRANSFORMER_UNITS = [\n",
    "    ENC_PROJECTION_DIM * 2,\n",
    "    ENC_PROJECTION_DIM,\n",
    "]  # Size of the transformer layers.\n",
    "DEC_TRANSFORMER_UNITS = [\n",
    "    DEC_PROJECTION_DIM * 2,\n",
    "    DEC_PROJECTION_DIM,\n",
    "]\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Number of persons\n",
    "NUM_PERSONS = ntrain.shape[0]  \n",
    "TRAIN_SIZE = ntrain.shape[0] \n",
    "TEST_SIZE = ntest.shape[0] \n",
    "VAL_SIZE = nval.shape[0] \n",
    "\n",
    "# Aparentemente para esse número de batch a acurácia binária cai para 60%.\n",
    "# Quando era 5 o número de batchs era de 90%. Irei testar\n",
    "BATCH_SIZE = 5 \n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "MASK_PROPORTION = 0.10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[..., np.newaxis]\n",
    "#test = test[..., np.newaxis]\n",
    "#val = val[..., np.newaxis]\n",
    "\n",
    "train = ntrain[..., np.newaxis]\n",
    "test = ntest[..., np.newaxis]\n",
    "val = nval[..., np.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTO)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(val)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskingEncoder(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        projection_dim=ENC_PROJECTION_DIM,\n",
    "        mask_proportion=MASK_PROPORTION,\n",
    "        downstream=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection_dim = projection_dim\n",
    "        self.mask_proportion = mask_proportion\n",
    "        self.downstream = downstream\n",
    "\n",
    "        # This is a trainable mask token initialized randomly from a normal\n",
    "        # distribution.\n",
    "        self.mask_token = tf.Variable(\n",
    "            tf.random.normal([1, 1]), trainable=True\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        (_, self.num_stats, _) = input_shape\n",
    "\n",
    "        # Create the projection layer for the stats.\n",
    "        self.projection = layers.Dense(units=self.projection_dim)\n",
    "\n",
    "        # Create the positional embedding layer.\n",
    "        self.position_embedding = layers.Embedding( \n",
    "            input_dim=self.num_stats, output_dim=self.projection_dim\n",
    "        )\n",
    "        #self.position_masking = layers.Masking(mask_value=-1.0)\n",
    "\n",
    "        # Number of stats that will be masked.\n",
    "        self.num_mask = int(self.mask_proportion * self.num_stats)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Get the positional embeddings.\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        positions = tf.range(start=0, limit=self.num_stats, delta=1)\n",
    "        pos_embeddings = self.position_embedding(positions[tf.newaxis, ...])\n",
    "        pos_embeddings = tf.tile(\n",
    "            pos_embeddings, [batch_size, 1, 1]\n",
    "        )  # (B, num_stats, projection_dim)\n",
    "\n",
    "        ## Embed the inputs.\n",
    "        input_embeddings = (\n",
    "            self.projection(inputs) + pos_embeddings\n",
    "        )  # (B, num_stats, projection_dim)        \n",
    "\n",
    "        if self.downstream:\n",
    "            return input_embeddings\n",
    "        else:\n",
    "            \n",
    "            mask_indices, unmask_indices = self.get_random_indices(batch_size)\n",
    "            # The encoder input is the unmasked patch embeddings. Here we gather\n",
    "            # all the inputs that should be unmasked.\n",
    "            #input_maskings = tf.reshape(input_maskings, (18, 1))\n",
    "            \n",
    "            unmasked_embeddings = tf.gather(\n",
    "                input_embeddings, unmask_indices, axis=1, batch_dims=1\n",
    "            )  # (B, unmask_numbers, projection_dim)\n",
    "\n",
    "            # Get the unmasked and masked position embeddings. We will need them\n",
    "            # for the decoder.\n",
    "            unmasked_positions = tf.gather(\n",
    "                input_embeddings, unmask_indices, axis=1, batch_dims=1\n",
    "            )  # (B, unmask_numbers, projection_dim)\n",
    "            masked_positions = tf.gather(\n",
    "                input_embeddings, mask_indices, axis=1, batch_dims=1\n",
    "            )  # (B, mask_numbers, projection_dim)\n",
    "\n",
    "            #TODO TENHO QUE ENTENDER AQUI***    \n",
    "            # Repeat the mask token number of mask times.\n",
    "            # Mask tokens replace the masks of the image.\n",
    "            mask_tokens = tf.repeat(self.mask_token, repeats=self.num_mask, axis=0)\n",
    "            mask_tokens = tf.repeat(\n",
    "                mask_tokens[tf.newaxis, ...], repeats=batch_size, axis=0\n",
    "            )\n",
    "\n",
    "            # Get the masked embeddings for the tokens.\n",
    "            masked_embeddings = self.projection(mask_tokens) + masked_positions\n",
    "            return (\n",
    "                unmasked_embeddings,  # Input to the encoder.\n",
    "                masked_embeddings,  # First part of input to the decoder.\n",
    "                unmasked_positions,  # Added to the encoder outputs.\n",
    "                mask_indices,  # The indices that were masked.\n",
    "                unmask_indices,  # The indices that were unmaksed.\n",
    "            )\n",
    "\n",
    "    def get_random_indices(self, batch_size):\n",
    "        # Create random indices from a uniform distribution and then split\n",
    "        # it into mask and unmask indices.\n",
    "        rand_indices = tf.argsort(\n",
    "            tf.random.uniform(shape=(batch_size, NUM_STATS)), axis=-1\n",
    "        )\n",
    "        mask_indices = rand_indices[:, : self.num_mask]\n",
    "        unmask_indices = rand_indices[:, self.num_mask :]\n",
    "        return mask_indices, unmask_indices\n",
    "\n",
    "    def generate_masked_image(self, inputs, unmask_indices):\n",
    "        # Choose a random patch and it corresponding unmask index.\n",
    "        idx = np.random.choice(inputs.shape[0])\n",
    "        patch = inputs[idx]\n",
    "        unmask_index = unmask_indices[idx]\n",
    "\n",
    "        # Build a numpy array of same shape as patch.\n",
    "        new_patch = -np.ones_like(patch)\n",
    "\n",
    "        # Iterate of the new_patch and plug the unmasked inputs.\n",
    "        count = 0\n",
    "        for i in range(unmask_index.shape[0]):\n",
    "            new_patch[unmask_index[i]] = patch[unmask_index[i]]\n",
    "        return new_patch, idx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the masking process in action on a sample person response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train\n",
    "\n",
    "\n",
    "# Create the masking encoder layer.\n",
    "masked_encoder = MaskingEncoder()\n",
    "\n",
    "# Get the embeddings and positions.\n",
    "(\n",
    "    unmasked_embeddings,\n",
    "    masked_embeddings,\n",
    "    unmasked_positions,\n",
    "    mask_indices,\n",
    "    unmask_indices,\n",
    ") = masked_encoder(inputs=inputs)\n",
    "\n",
    "\n",
    "# Show a maksed patch image.\n",
    "new_masked, random_index = masked_encoder.generate_masked_image(inputs, unmask_indices)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 40))\n",
    "\n",
    "min_val, max_val = -1, 1\n",
    "\n",
    "cmap = plt.cm.Pastel1\n",
    "\n",
    "ax[0].matshow(new_masked, cmap=cmap)\n",
    "\n",
    "rows = new_masked.shape[0]\n",
    "cols = new_masked.shape[1]\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        c = new_masked[i,j]\n",
    "        ax[0].text(j, i, str(c), va='center', ha='center')\n",
    "\n",
    "ax[0].xaxis.set_visible(False)\n",
    "ax[0].set_title('Masked')\n",
    "\n",
    "cmp2 = mplt.colors.ListedColormap(['moccasin', 'whitesmoke'])\n",
    "\n",
    "original = train[random_index].reshape(train.shape[1], 1)\n",
    "ax[1].matshow(original, cmap=cmp2)\n",
    "\n",
    "rows = original.shape[0]\n",
    "cols = original.shape[1]\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        c = original[i,j]\n",
    "        ax[1].text(j, i, str(c), va='center', ha='center')\n",
    "\n",
    "ax[1].xaxis.set_visible(False)\n",
    "ax[1].set_title('Original')\n",
    "\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#plt.subplot(1, 2, 1)\n",
    "#img = patch_layer.reconstruct_from_patch(new_patch)\n",
    "#plt.imshow(keras.utils.array_to_img(img))\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(\"Masked\")\n",
    "#plt.subplot(1, 2, 2)\n",
    "#img = augmented_images[random_index]\n",
    "#plt.imshow(keras.utils.array_to_img(img))\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(\"Original\")\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "This serves as the fully connected feed forward network of the transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, dropout_rate, hidden_units):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE encoder\n",
    "\n",
    "The MAE encoder is ViT. The only point to note here is that the encoder outputs a layer normalized output.## Enconder (after masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(num_heads=ENC_NUM_HEADS, num_layers=ENC_LAYERS):\n",
    "    inputs = layers.Input((None, ENC_PROJECTION_DIM))\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=ENC_PROJECTION_DIM, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
    "\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=ENC_TRANSFORMER_UNITS, dropout_rate=0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add()([x3, x2])\n",
    "\n",
    "    outputs = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
    "    return keras.Model(inputs, outputs, name=\"mae_encoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE decoder\n",
    "\n",
    "The authors point out that they use an asymmetric autoencoder model. They use a lightweight decoder that takes \"<10% computation per token vs. the encoder\". We are not specific with the \"<10% computation\" in our implementation but have used a smaller decoder (both in terms of depth and projection dimensions).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(\n",
    "    num_layers=DEC_LAYERS, num_heads=DEC_NUM_HEADS, output_size=NUM_STATS\n",
    "):\n",
    "    inputs = layers.Input((NUM_STATS, ENC_PROJECTION_DIM))\n",
    "    x = layers.Dense(DEC_PROJECTION_DIM)(inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=DEC_PROJECTION_DIM, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
    "\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=DEC_TRANSFORMER_UNITS, dropout_rate=0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add()([x3, x2])\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    pre_final = layers.Dense(units=output_size, activation=\"sigmoid\")(x)\n",
    "    outputs = layers.Reshape((output_size, 1))(pre_final)\n",
    "\n",
    "    return keras.Model(inputs, outputs, name=\"mae_decoder\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAutoencoder(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        masking_encoder,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.masking_encoder = masking_encoder\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def calculate_loss(self, input):\n",
    "\n",
    "        # Encode the inputs.\n",
    "        (\n",
    "            unmasked_embeddings,\n",
    "            masked_embeddings,\n",
    "            unmasked_positions,\n",
    "            mask_indices,\n",
    "            unmask_indices,\n",
    "        ) = self.masking_encoder(input)\n",
    "\n",
    "        # Pass the unmaksed patche to the encoder.\n",
    "        encoder_outputs = self.encoder(unmasked_embeddings)\n",
    "\n",
    "        # Create the decoder inputs.\n",
    "        encoder_outputs = encoder_outputs + unmasked_positions\n",
    "        decoder_inputs = tf.concat([encoder_outputs, masked_embeddings], axis=1)\n",
    "\n",
    "        # Decode the inputs.\n",
    "        decoder_outputs = self.decoder(decoder_inputs)\n",
    "        decoder_masked = decoder_outputs\n",
    "\n",
    "        loss_patch = tf.gather(input, mask_indices, axis=1, batch_dims=1)\n",
    "        loss_output = tf.gather(decoder_masked, mask_indices, axis=1, batch_dims=1)\n",
    "\n",
    "        # Compute the total loss.\n",
    "        total_loss = self.compiled_loss(loss_patch, loss_output)\n",
    "\n",
    "        return total_loss, loss_patch, loss_output\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, loss_patch, loss_output = self.calculate_loss(inputs)\n",
    "\n",
    "        # Apply gradients.\n",
    "        train_vars = [\n",
    "            self.masking_encoder.trainable_variables,\n",
    "            self.encoder.trainable_variables,\n",
    "            self.decoder.trainable_variables,\n",
    "        ]\n",
    "        grads = tape.gradient(total_loss, train_vars)\n",
    "        tv_list = []\n",
    "        for (grad, var) in zip(grads, train_vars):\n",
    "            for g, v in zip(grad, var):\n",
    "                tv_list.append((g, v))\n",
    "        self.optimizer.apply_gradients(tv_list)\n",
    "\n",
    "        # Report progress.\n",
    "        self.compiled_metrics.update_state(loss_patch, loss_output)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, inputs):\n",
    "        total_loss, loss_patch, loss_output = self.calculate_loss(inputs)\n",
    "\n",
    "        # Update the trackers.\n",
    "        self.compiled_metrics.update_state(loss_patch, loss_output)\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_encoder = MaskingEncoder()\n",
    "encoder = create_encoder()\n",
    "decoder = create_decoder()\n",
    "\n",
    "mae_model = MaskedAutoencoder(\n",
    "    masking_encoder=masking_encoder,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training callback "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a batch of test inputs to measure model's progress.\n",
    "\n",
    "test_items = next(iter(test_ds))\n",
    "\n",
    "\n",
    "class TrainMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, epoch_interval=None):\n",
    "        self.epoch_interval = epoch_interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch_interval and epoch % self.epoch_interval == 0:\n",
    "            (\n",
    "                test_unmasked_embeddings,\n",
    "                test_masked_embeddings,\n",
    "                test_unmasked_positions,\n",
    "                test_mask_indices,\n",
    "                test_unmask_indices,\n",
    "            ) = self.model.masking_encoder(test_items)\n",
    "            test_encoder_outputs = self.model.encoder(test_unmasked_embeddings)\n",
    "            test_encoder_outputs = test_encoder_outputs + test_unmasked_positions\n",
    "            test_decoder_inputs = tf.concat(\n",
    "                [test_encoder_outputs, test_masked_embeddings], axis=1\n",
    "            )\n",
    "            test_decoder_outputs = self.model.decoder(test_decoder_inputs)\n",
    "\n",
    "            # Show a maksed patch image.\n",
    "            test_masked, idx = self.model.masking_encoder.generate_masked_image(\n",
    "                test_items, test_unmask_indices\n",
    "            )\n",
    "            print(f\"\\nIdx chosen: {idx}\")\n",
    "            original = tf.reshape(test_items[idx], (test_items.shape[1], 1)).numpy()\n",
    "            #test_masked_image = self.model.patch_layer.reconstruct_from_patch(\n",
    "            #    test_masked_patch\n",
    "            #)\n",
    "            reconstructed = test_decoder_outputs[idx]\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 40))\n",
    "            min_val, max_val = -1, 1\n",
    "\n",
    "            rows = original.shape[0]\n",
    "            cols = original.shape[1]\n",
    "\n",
    "            cmap = plt.cm.Pastel1\n",
    "            cmp2 = mplt.colors.ListedColormap(['moccasin', 'whitesmoke'])\n",
    "\n",
    "            ax[0].matshow(original, cmap=cmp2)\n",
    "            ax[0].xaxis.set_visible(False)\n",
    "            ax[0].set_title(f\"Original: {epoch:03d}\")\n",
    "\n",
    "            ax[1].matshow(test_masked, cmap=cmap)\n",
    "            ax[1].xaxis.set_visible(False)\n",
    "            ax[1].set_title(f\"Masked: {epoch:03d}\")\n",
    "\n",
    "            ax[2].matshow(reconstructed, cmap=cmp2)\n",
    "            ax[2].xaxis.set_visible(False)\n",
    "            ax[2].set_title(f\"Reconstructed: {epoch:03d}\")\n",
    "\n",
    "            for i in range(rows):\n",
    "                for j in range(cols):\n",
    "                    c1 = original[i,j]\n",
    "                    ax[0].text(j, i, str(c1), va='center', ha='center')\n",
    "                    c2 = test_masked[i,j]\n",
    "                    ax[1].text(j, i, str(c2), va='center', ha='center')\n",
    "                    c3 = reconstructed[i,j]\n",
    "                    if c3.numpy() < 0.5:\n",
    "                        c3 = 0\n",
    "                    else:\n",
    "                        c3 = 1\n",
    "                    ax[2].text(j, i, str(c3), va='center', ha='center')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code is taken from:\n",
    "# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.\n",
    "\n",
    "\n",
    "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
    "    ):\n",
    "        super(WarmUpCosine, self).__init__()\n",
    "\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.pi = tf.constant(np.pi)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if self.total_steps < self.warmup_steps:\n",
    "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
    "\n",
    "        cos_annealed_lr = tf.cos(\n",
    "            self.pi\n",
    "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
    "            / float(self.total_steps - self.warmup_steps)\n",
    "        )\n",
    "        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
    "\n",
    "        if self.warmup_steps > 0:\n",
    "            if self.learning_rate_base < self.warmup_learning_rate:\n",
    "                raise ValueError(\n",
    "                    \"Learning_rate_base must be larger or equal to \"\n",
    "                    \"warmup_learning_rate.\"\n",
    "                )\n",
    "            slope = (\n",
    "                self.learning_rate_base - self.warmup_learning_rate\n",
    "            ) / self.warmup_steps\n",
    "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
    "            learning_rate = tf.where(\n",
    "                step < self.warmup_steps, warmup_rate, learning_rate\n",
    "            )\n",
    "        return tf.where(\n",
    "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
    "        )\n",
    "\n",
    "\n",
    "total_steps = int((train.shape[0] / BATCH_SIZE) * NUM_EPOCHS)\n",
    "warmup_epoch_percentage = 0.15\n",
    "warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=LEARNING_RATE,\n",
    "    total_steps=total_steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "lrs = [scheduled_lrs(step) for step in range(total_steps)]\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Assemble the callbacks.\n",
    "train_callbacks = [TrainMonitor(epoch_interval=10)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = keras.optimizers.experimental.AdamW(learning_rate=scheduled_lrs, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Compile and pretrain the model.\n",
    "mae_model.compile(\n",
    "    optimizer=optimizer, loss=keras.losses.MeanSquaredError(), metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = mae_model.fit(\n",
    "    train_ds, \n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_ds, \n",
    "    callbacks=train_callbacks,\n",
    ")\n",
    "\n",
    "# Measure its performance.\n",
    "loss, ba = mae_model.evaluate(test_ds)\n",
    "print(f\"Loss: {loss:.2f}\")\n",
    "print(f\"Binary Accuracy: {ba:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate masked data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_masked_data(inputs, unmask_indices):\n",
    "    # Build a numpy array of same shape as patch.\n",
    "    unmask = unmask_indices.numpy()\n",
    "    new_data = -np.ones_like(inputs)\n",
    "\n",
    "    # Iterate of the new_patch and plug the unmasked inputs.\n",
    "    #for i in range(unmask_indices.shape[0]):\n",
    "    #    new_patch[unmask_index[i]] = patch[unmask_index[i]]\n",
    "    #eturn new_patch, idx\n",
    "\n",
    "    for idx in range(inputs.shape[0]):\n",
    "        new_data[idx][unmask[idx]] = inputs[idx][unmask[idx]]\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for each replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_unmasked_embeddings,\n",
    "    train_masked_embeddings,\n",
    "    train_unmasked_positions,\n",
    "    train_mask_indices,\n",
    "    train_unmask_indices,\n",
    ") = mae_model.masking_encoder(train)\n",
    "train_encoder_outputs = mae_model.encoder(train_unmasked_embeddings)\n",
    "train_encoder_outputs = train_encoder_outputs + train_unmasked_positions\n",
    "train_decoder_inputs = tf.concat(\n",
    "    [train_encoder_outputs, train_masked_embeddings], axis=1\n",
    ")\n",
    "train_decoder_outputs = mae_model.decoder(train_decoder_inputs)\n",
    "\n",
    "masked = generate_masked_data(train, train_unmask_indices)\n",
    "\n",
    "pred = train_decoder_outputs.numpy()\n",
    "pred = np.squeeze(pred, axis=2)\n",
    "\n",
    "m = np.squeeze(masked, axis=2)\n",
    "\n",
    "np.savetxt('output_data/10_missing/y/Y_rep1_transformer_10_missing.csv', pred, delimiter=';')\n",
    "np.savetxt('output_data/10_missing/masked/Masked_rep1_10_missing.csv', m,  delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 101):\n",
    "    data = pd.read_csv('input_data/y/Yrep' + str(i) + '.csv', sep=';', header=None)\n",
    "    data = data.values.reshape((90, 10000)).transpose()\n",
    "\n",
    "    (\n",
    "        train_unmasked_embeddings,\n",
    "        train_masked_embeddings,\n",
    "        train_unmasked_positions,\n",
    "        train_mask_indices,\n",
    "        train_unmask_indices,\n",
    "    ) = mae_model.masking_encoder(train)\n",
    "    train_encoder_outputs = mae_model.encoder(train_unmasked_embeddings)\n",
    "    train_encoder_outputs = train_encoder_outputs + train_unmasked_positions\n",
    "    train_decoder_inputs = tf.concat(\n",
    "        [train_encoder_outputs, train_masked_embeddings], axis=1\n",
    "    )\n",
    "    train_decoder_outputs = mae_model.decoder(train_decoder_inputs)\n",
    "\n",
    "    masked = generate_masked_data(train, train_unmask_indices)\n",
    "\n",
    "    pred = train_decoder_outputs.numpy()\n",
    "    pred = np.squeeze(pred, axis=2)\n",
    "\n",
    "    m = np.squeeze(masked, axis=2)\n",
    "\n",
    "    np.savetxt('output_data/10_missing/y/Y_rep' + str(i) + '_transformer_10_missing.csv', pred, delimiter=';')\n",
    "    np.savetxt('output_data/10_missing/masked/Masked_rep' + str(i) + '_10_missing.csv', m,  delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('data/Yrep1.csv', sep=';', header=None)\n",
    "original = original.values.reshape((180, 10000)).transpose()\n",
    "transformer = pd.read_csv('output/y_transformer_10_missing_180x21.csv', sep=';', header=None)\n",
    "masked = pd.read_csv('output/masked_10_missing_180x21.csv', sep=';', header=None)\n",
    "claudia = pd.read_csv('output/y_claudia_10_missing_180x21.csv', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original.shape)\n",
    "print(transformer.shape)\n",
    "print(claudia.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld = claudia.iloc[:, 1].values.reshape((8000, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = np.ones_like(transformer.values)\n",
    "trn[transformer.values < 0.5] = 0\n",
    "print(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_indices = []\n",
    "\n",
    "for i in range(masked.shape[0]):\n",
    "    d = []\n",
    "    for j in range(masked.shape[1]):\n",
    "        if masked.values[i,j] == -1:\n",
    "            d.append(j)        \n",
    "    masked_indices.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_indices = np.array(masked_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = np.ndarray(masked_indices.shape)\n",
    "t = np.ndarray(masked_indices.shape)\n",
    "c = np.ndarray(masked_indices.shape)\n",
    "\n",
    "#orig = original.values.reshape((10000, 180))\n",
    "orig = original[:8000, :]\n",
    "print(orig.shape)\n",
    "\n",
    "for i in range(masked_indices.shape[0]):\n",
    "    o[i] = orig[i, :][masked_indices[i,:]]\n",
    "    t[i] = trn[i, :][masked_indices[i,:]]\n",
    "    c[i] = cld[i, :][masked_indices[i,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o.shape)\n",
    "print(t.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'original': o.flatten(), 'transformer': t.flatten()}\n",
    "data1 = {'original': o.flatten(), 'claudia': c.flatten()}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "cm = pd.crosstab(df['original'], df['transformer'])\n",
    "cm1 = pd.crosstab(df1['original'], df1['claudia'])\n",
    "\n",
    "print(cm)\n",
    "print(cm1)\n",
    "\n",
    "cmp = pd.crosstab(df['original'], df['transformer']).apply(lambda s: (s/s.sum() * 100), axis=1)\n",
    "cmp1 = pd.crosstab(df1['original'], df1['claudia']).apply(lambda r: (r/r.sum() * 100), axis=1)\n",
    "\n",
    "print(cmp)\n",
    "print(cmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "924285c36e9c91e77dd67ccd6618b5b801447ab41be1cbc841fddd0b5e954220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
